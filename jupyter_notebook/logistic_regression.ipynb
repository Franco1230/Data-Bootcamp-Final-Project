{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV\n",
    "df = pd.read_csv(\"../cleaned_data/cleaned_house_crime_school.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features to be used as X values.\n",
    "X = df.drop([\"Price\", \"Suburb\", \"Date\", \"Address\", \"Type\", \"Postcode\", \"CouncilArea\", \"Lattitude\", \"Longtitude\", \"Regionname\", \"Distance\", \"CrimeRate\"], axis = \"columns\")\n",
    "y = df[\"Price\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET housing stats\n",
    "total_houses = len(df)\n",
    "max_value = df[\"Price\"].describe()[\"max\"]\n",
    "min_value = df[\"Price\"].describe()[\"min\"]\n",
    "print(f\"Total houses: {total_houses}\")\n",
    "print(f\"Highest price: {max_value}\")\n",
    "print(f\"Lowest price: {min_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into test and train data using `train_test_split` with test size of 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.33)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(solver = \"newton-cg\", multi_class = \"auto\")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "training_score = classifier.score(X_train, y_train)\n",
    "base_accuracy = classifier.score(X_test, y_test)\n",
    "\n",
    "print(f\"LogisticRegression training Data Score: {training_score}\")\n",
    "print(f\"LogisticRegression testing Data Score: {base_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "param_grid = {\"C\": [0.1, 1, 10],\n",
    "              \"max_iter\": [1000, 5000, 10000]}\n",
    "grid = GridSearchCV(classifier, param_grid, error_score = \"raise\", verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best grid params: {grid.best_params_}\")\n",
    "print(f\"Best grid score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned parameters\n",
    "C = grid.best_params_[\"C\"]\n",
    "max_iter = grid.best_params_[\"max_iter\"]\n",
    "\n",
    "# Tuned model\n",
    "tuned_model = LogisticRegression(solver = \"newton-cg\",\n",
    "                                 multi_class = \"auto\",\n",
    "                                 C = C,\n",
    "                                 max_iter = max_iter)\n",
    "tuned_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "tuned_model_score = tuned_model.score(X_train_scaled, y_train)\n",
    "tuned_accuracy = tuned_model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Training Data Score: {tuned_model_score}\")\n",
    "print(f\"Testing Data Score: {tuned_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = tuned_model.predict(X_test)\n",
    "classifications = y_test.unique().tolist()\n",
    "\n",
    "prediction_actual = {\"Actual\": y_test,\n",
    "                     \"Prediction\": predictions}\n",
    "\n",
    "prediction_df = pd.DataFrame(prediction_actual)\n",
    "prediction_df = prediction_df.set_index(\"Actual\").reset_index()\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = {\"\": [\"Base Model\", \"Tuned Model\"],\n",
    "               \"Accuracy\": [f\"%s\" % round(base_accuracy, 3), f\"%s\" % round(tuned_accuracy, 3)]}\n",
    "\n",
    "evaluations_df = pd.DataFrame(evaluations)\n",
    "evaluations_df = evaluations_df.set_index(\"\")\n",
    "\n",
    "evaluations_df.to_csv(\"../evaluations/random_forest_eval.csv\")\n",
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../models/random_forest.sav\"\n",
    "joblib.dump(tuned_model, filename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a19ada5e1fb28d2398124d72f5220c6963263362c245ad7923c8641f46f6c7d1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('pythonData': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
